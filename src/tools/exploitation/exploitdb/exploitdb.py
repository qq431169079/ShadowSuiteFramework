#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# exploitdb.py - Search exploits from exploit-db.com
#
# Version: 1.0
# Author: Mathieu D. (mattoufoutu)
# License: FreeBSD
#

from __future__ import print_function
import cmd
import csv
import os
import re
import shutil
import sys
from collections import defaultdict
from copy import copy
try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen
from zipfile import ZipFile

CURRENT_DIR = os.path.realpath(os.path.dirname("."))
EXPLOITS_DIR_ORIG = os.path.join(CURRENT_DIR, 'exploit-database-master')
EXPLOITS_DIR = os.path.join(CURRENT_DIR, 'exploits')
EXPLOITS_CSV = os.path.join(EXPLOITS_DIR, 'files.csv')
ARCHIVE_PATH = os.path.join(CURRENT_DIR, 'master.zip')
LATEST_PATH = os.path.join(CURRENT_DIR, '.latest')
ARCHIVE_URL = "https://github.com/offensive-security/exploit-database/archive/master.zip"


class ExploitSearch(cmd.Cmd):
    prompt = '\033[1;31mexploitdb\033[0m\033[1;32m>\033[0m '
    intro = (
        '\n \033[40m\033[1;37m'
        '-=[ exploitdb.py - Search exploits from exploit-db.com ]='
        '-\033[0m\n'
    )
    fields = ('id', 'file', 'description', 'date', 'author', 'platform', 'type', 'port')
    search_regexes = {
        'plain': [
            re.compile(r'(\w+)?:(?!r[\'"])([^ \'"]+)?'),
            re.compile(r'(\w+)?:(?:\'|")([^"\']+)?')
        ],
        'regex': [
            re.compile(r'(\w+):r(?:\'|")([^"\']+)')
        ]
    }
    highlighted_fields_map = {
        'id': ['id'],
        'description': ['description'],
        'file': ['type', 'platform']
    }

    def __init__(self, csv_file=EXPLOITS_CSV):
        self.csv_file = csv_file
        self.exploits = []
        self.load_csv()
        self.fields_value_completion = {
            'platform': {e['platform'] for e in self.exploits},
            'type': {e['type'] for e in self.exploits},
            'port': {e['port'] for e in self.exploits}
        }
        cmd.Cmd.__init__(self)

    @staticmethod
    def get_archive_etag():
        resp = urlopen(ARCHIVE_URL)
        try:
            etag = resp.info().getgeaders("ETag")[0].strip('"')
        except AttributeError:
            etag = resp.info().get("ETag")[0].strip('"')
        return etag

    @staticmethod
    def download_archive():
        resp = urlopen(ARCHIVE_URL)
        try:
            file_size = int(resp.info().getheaders("Content-Length")[0])
        except AttributeError:
            # Python 3 compat
            file_size = int(resp.info().get("Content-Length"))
        downloaded_size = 0
        block_size = 4096
        with open(ARCHIVE_PATH, 'wb') as outfile:
            buff = resp.read(block_size)
            while buff:
                outfile.write(buff)
                downloaded_size += len(buff)
                downloaded_part = float(downloaded_size) / file_size
                progress_size = int(downloaded_part * 50)
                status = '[{0}{1}] {2:.2%}'.format(
                    '#' * progress_size,
                    ' ' * (50 - progress_size),
                    downloaded_part
                )
                sys.stdout.write(status)
                sys.stdout.write('\b' * (len(status) + 1))
                buff = resp.read(block_size)
            sys.stdout.write('\n')

    def parse_args(self, args):
        search_args = {
            'plain': [],
            'regex': []
        }
        if ':' not in args:
            search_args['plain'].append(('description', args))
        else:
            for search_type, regexes in self.search_regexes.items():
                for regex in regexes:
                    result = regex.findall(args)
                    if result:
                        for field_name, pattern in result:
                            if field_name not in self.fields:
                                pattern = '{}:{}'.format(field_name, pattern)
                                search_args['plain'].append(('description', pattern))
                            else:
                                search_args[search_type].append((field_name, pattern))
        return search_args

    def load_csv(self, startup=True):
        if not os.path.exists(self.csv_file):
            print("Database not found, updating now!\n")
            etag = self.get_archive_etag()
            self.updatedb(etag)
        else:
            if startup:
                print("Checking for new database version... ", end='')
                with open(LATEST_PATH) as infile:
                    current_etag = infile.read().strip()
                latest_etag = self.get_archive_etag()
                if latest_etag != current_etag:
                    print("UPDATE FOUND")
                    self.updatedb(latest_etag)
                else:
                    print("OK")
        with open(self.csv_file) as infile:
            reader = csv.reader(infile)
            for index, entry in enumerate(reader):
                if index == 0:
                    header = entry
                    continue
                exploit = dict(zip(header, entry))
                if exploit['port'] == '0':
                    exploit['port'] = 'n/a'
                if not exploit['platform']:
                    exploit['platform'] = 'n/a'
                if '//' in exploit['file']:
                    exploit['file'] = exploit['file'].replace('//', '/')
                self.exploits.append(exploit)

    def search(self, search_params):
        matches = []
        args = self.parse_args(search_params)
        for exploit in self.exploits:
            matching = True
            for search_type, search_args in args.items():
                if search_type == 'plain':
                    for field_name, pattern in search_args:
                        if pattern.lower() not in exploit[field_name].lower():
                            matching = False
                            break
                    if not matching:
                        break
                elif search_type == 'regex':
                    for field_name, pattern in search_args:
                        if re.search(pattern, exploit[field_name], flags=re.I) is None:
                            matching = False
                            break
                    if not matching:
                        break
            if matching:
                matches.append((exploit, args))
        return matches

    def do_search(self, line):
        """
        search - search database for exploits
        Usage: search field:pattern [field:pattern, ...]
        """
        results = self.search(line)
        for result, args in results:
            flattened_args = defaultdict(list)
            for search_type in ('plain', 'regex'):
                for k, v in args[search_type]:
                    flattened_args[k].append(v)
            result = copy(result)
            for field_name, search_vals in self.highlighted_fields_map.items():
                for search_val in search_vals:
                    if search_val in flattened_args:
                        for pattern in flattened_args[search_val]:
                            re_pattern = pattern
                            if field_name not in args['regex']:
                                re_pattern = re.escape(pattern)
                            result[field_name] = re.sub(
                                re_pattern,
                                lambda matchobj: '\033[1;33m' + matchobj.group(0) + '\033[0m',
                                result[field_name],
                                flags=re.I,
                                count=1
                            )
            result_str = "[{}] {} - {}".format(result['id'], result['description'], result['file'])
            print(result_str)
        print('')

    def complete_search(self, text, line, begidx, endidx):
        last_arg = line.split()[-1]
        if last_arg:
            if ':' in last_arg:
                field_name, pattern = last_arg.split(':')
                if pattern:
                    return [
                        f for f in self.fields_value_completion[field_name]
                        if f.startswith(pattern)
                    ]
                return [f for f in self.fields_value_completion[field_name]]
            return [f + ':' for f in self.fields if f.startswith(last_arg)]
        return [f + ':' for f in self.fields]

    def info(self, exploit_id):
        for exploit in self.exploits:
            if exploit['id'] == exploit_id:
                return exploit
        return None

    def do_info(self, line):
        """
        info - get details about given exploit
        Usage: info exploit_id
        """
        result = self.info(line)
        if result is None:
            print("No exploit with this ID: {}\n".format(line))
            return
        desc_len = len(result['description'])
        fstring = "{{:<13}} | {{:<{}}}".format(desc_len)
        print(("{{:=^{}}}".format(desc_len + 17)).format(' #%s ' % result['id']))
        print(fstring.format(' Filename ', result['file'] + ' '))
        print(fstring.format(' Description ', result['description'] + ' '))
        print(fstring.format(' Date ', result['date'] + ' '))
        print(fstring.format(' Author ', result['author'] + ' '))
        print(fstring.format(' Platform ', result['platform'] + ' '))
        print(fstring.format(' Type ', result['type'] + ' '))
        print(fstring.format(' Port ', result['port'] + ' '))
        print((desc_len + 17) * '=' + '\n')

    def complete_info(self, text, line, begidx, endidx):
        if not text:
            return [e['id'] for e in self.exploits]
        else:
            return [e['id'] for e in self.exploits if e['id'].startswith(text)]

    def updatedb(self, etag):
        print("Downloading latest exploits archive...")
        self.download_archive()
        print("Extracting files...")
        if os.path.exists(EXPLOITS_DIR):
            shutil.rmtree(EXPLOITS_DIR)
            os.mkdir(EXPLOITS_DIR)
        with ZipFile(ARCHIVE_PATH) as infile:
            infile.extractall(path=CURRENT_DIR)
        os.remove(ARCHIVE_PATH)
        os.rename(EXPLOITS_DIR_ORIG, EXPLOITS_DIR)
        os.chmod(EXPLOITS_CSV, 0o644)
        self.exploits = []
        with open(LATEST_PATH, 'w') as outfile:
            outfile.write(etag)
        self.load_csv(startup=False)
        print("OK\n")

    def do_updatedb(self, line):
        """
        updatedb - update local exploits database
        Usage: updatedb
        """
        etag = self.get_archive_etag()
        self.updatedb(etag)

    def do_show(self, line):
        """
        show - display the content of an exploit file
        Usage: show exploit_id|exploit_path
        """
        if line.isdigit():
            field = 'id'
        else:
            field = 'file'
        found = False
        for exploit in self.exploits:
            if exploit[field] == line:
                found = True
                break
        if not found:
            print("Exploit not found: {}\n".format(line))
        else:
            sploit_path = os.path.join(EXPLOITS_DIR, exploit['file'])
            with open(sploit_path) as infile:
                print(infile.read())
                print('')

    def complete_show(self, text, line, begidx, endidx):
        completions = []
        if not text:
            completions.extend([s['id'] for s in self.exploits])
            completions.extend([s['file'] for s in self.exploits])
        else:
            completions.extend([s['id'] for s in self.exploits if s['id'].startswith(text)])
            completions.extend([s['file'] for s in self.exploits if s['file'].startswith(text)])
        return completions

    @staticmethod
    def do_EOF(self):
        return True


def main(restarted=False):
    es = ExploitSearch()
    if restarted:
        es.intro = '\n'
    try:
        es.cmdloop()
    except KeyboardInterrupt:
        main(True)


if __name__ == '__main__':
    main()
